{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YVBFFHsTWlJjnOQ3SlhqQz9MZC5Q0V-h","authorship_tag":"ABX9TyPOnHyVq2Gd6GS9oa/c/PLu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xNaVFUAtuuSg","executionInfo":{"status":"ok","timestamp":1711780156363,"user_tz":-330,"elapsed":48785,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"f4c03ea2-60cd-415f-d1e1-ad5ebe1247b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/810.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/810.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n","  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n","  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n","Collecting openai\n","  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.14.3\n","Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n","Installing collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.8.0\n","Collecting tiktoken\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.6.0\n"]}],"source":["!pip install langchain\n","!pip install openai\n","!pip install PyPDF2\n","!pip install faiss-cpu\n","!pip install tiktoken"]},{"cell_type":"code","source":["from PyPDF2 import PdfReader\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"],"metadata":{"id":"Lt5lNqp4vR5c","executionInfo":{"status":"ok","timestamp":1711780157553,"user_tz":-330,"elapsed":1194,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Get your API keys from openai, you will need to create an account.\n","# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = \"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\""],"metadata":{"id":"LJcScZnlvhNX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"laqumehi3hKJ","executionInfo":{"status":"ok","timestamp":1702988614094,"user_tz":-330,"elapsed":3993,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"57e6c8ff-38b9-4a95-d82d-d8c87cb43fee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# connect your Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IR3DFjvSwM34","executionInfo":{"status":"ok","timestamp":1702988624095,"user_tz":-330,"elapsed":6984,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"ac254fb2-e3c4-494b-a99e-53bbe8be52ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# location of the pdf file/files.\n","reader = PdfReader('/content/IoT Based Smart Gloves for Disabled People.pdf')"],"metadata":{"id":"K851eURHwalZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh1-BBHlwd7i","executionInfo":{"status":"ok","timestamp":1702988631272,"user_tz":-330,"elapsed":628,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"9135690d-edd2-4676-de7e-89a9e8739e99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PyPDF2._reader.PdfReader at 0x7f9e288ecee0>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# read data from the file and put them into a variable called raw_text\n","raw_text = ''\n","for i, page in enumerate(reader.pages):\n","    text = page.extract_text()\n","    if text:\n","        raw_text += text"],"metadata":{"id":"cKTJC6g9wgnN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# raw_text\n","raw_text[:100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"9V84Ij5Swjq6","executionInfo":{"status":"ok","timestamp":1702988638114,"user_tz":-330,"elapsed":462,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"2d45e462-6b54-4c54-8c6c-aeb764f42e36"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Project\\nTitle:\\nIoT-Based\\nSmart\\nGloves\\nfor\\nDisabled\\nPeople\\nIntroduction:\\nThe\\n\"IoT\\nBased\\nSmart\\nGloves\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits.\n","\n","text_splitter = CharacterTextSplitter(\n","    separator = \"\\n\",\n","    chunk_size = 1000,\n","    chunk_overlap  = 200,\n","    length_function = len,\n",")\n","texts = text_splitter.split_text(raw_text)"],"metadata":{"id":"k90zOn6PwunE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(texts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyWkOtuQw03U","executionInfo":{"status":"ok","timestamp":1702988645260,"user_tz":-330,"elapsed":433,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"caf77cd6-fbc4-4c0a-e3e8-d8ce673a5d0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["texts[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"UnlgQOZPw1re","executionInfo":{"status":"ok","timestamp":1702988649256,"user_tz":-330,"elapsed":587,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"518fdbb8-d6e0-45f4-9fea-eeecdd31eefe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Project\\nTitle:\\nIoT-Based\\nSmart\\nGloves\\nfor\\nDisabled\\nPeople\\nIntroduction:\\nThe\\n\"IoT\\nBased\\nSmart\\nGloves\\nfor\\nDisabled\\nPeople\"\\nproject\\naims\\nto\\nprovide\\nan\\ninnovative\\nsolution\\nto\\nenhance\\nthe\\nquality\\nof\\nlife\\nfor\\nindividuals\\nwith\\nspeech\\nand\\nmobility\\nimpairments.\\nThe\\nproject\\nintegrates\\nflex\\nsensors\\nto\\ndetect\\nsign\\nlanguage\\ngestures,\\nenabling\\ncommunication,\\nhome\\nautomation\\ncontrolled\\nby\\nhand\\nmovements,\\nand\\nobstacle\\ndetection\\nusing\\nultrasonic\\nsensors\\nto\\nensure\\nsafe\\nnavigation.\\nAbstract:\\nThe\\n\"IoT-Based\\nSmart\\nGloves\\nfor\\nDisabled\\nPeople\"\\nproject\\nrepresents\\na\\ngroundbreaking\\nendeavor\\nin\\nassistive\\ntechnology ,\\naimed\\nat\\nsignificantly\\nimproving\\nthe\\nlives\\nof\\nindividuals\\nwith\\nspeech\\nand\\nmobility\\nimpairments.\\nThis\\nproject\\nintroduces\\na\\ncomprehensive\\nsolution\\nthat\\nencompasses\\ncommunication,\\nhome\\nautomation,\\nand\\nsafety .\\nThe\\ndevelopment\\nof\\nthese\\nsmart\\ngloves\\nrevolves\\naround\\ntwo\\nprimary\\nsensor\\ntypes:\\nflex\\nsensors\\nand\\nultrasonic\\nsensors.\\nThe\\nflex\\nsensors,\\nmeticulously\\nplaced\\non\\nthe\\nfingers\\nof\\nthe\\ngloves,\\ncapture'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["texts[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"r47AI5Rlw5Wv","executionInfo":{"status":"ok","timestamp":1702988652359,"user_tz":-330,"elapsed":489,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"202abce4-832c-4aca-feff-ff14aabe614a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The\\ndevelopment\\nof\\nthese\\nsmart\\ngloves\\nrevolves\\naround\\ntwo\\nprimary\\nsensor\\ntypes:\\nflex\\nsensors\\nand\\nultrasonic\\nsensors.\\nThe\\nflex\\nsensors,\\nmeticulously\\nplaced\\non\\nthe\\nfingers\\nof\\nthe\\ngloves,\\ncapture\\nthe\\nnuanced\\nmovements\\nof\\nthe\\nhand\\nduring\\nsign\\nlanguage\\ngestures.\\nThese\\nsensors\\nconvert\\nphysical\\nfinger\\nbending\\ninto\\nelectrical\\nsignals,\\nwhich\\nare\\nthen\\nprocessed\\nby\\na\\nmicrocontroller .\\nThe\\nmicrocontroller\\nemploys\\nadvanced\\nalgorithms\\nto\\ntranslate\\nthe\\nflex\\nsensor\\ndata\\ninto\\ntext\\nor\\nspeech\\noutput,\\nenabling\\nseamless\\ncommunication\\nbetween\\nthe\\nuser\\nand\\nothers.\\nBeyond\\ncommunication,\\nthese\\nsmart\\ngloves\\nextend\\ntheir\\nutility\\ninto\\nthe\\nrealm\\nof\\nhome\\nautomation.\\nUsers\\ncan\\ncontrol\\nvarious\\nhome\\ndevices\\nand\\nappliances\\nthrough\\nspecific\\nhand\\nmovements,\\ngranting\\nthem\\nnewfound\\nindependence\\nand\\nconvenience.\\nThe\\nintegration\\nof\\nactuators\\nand\\na\\ncommunication\\nmodule\\nensures\\nthat\\nthese\\ncommands\\nare\\nexecuted\\naccurately\\nand\\nwirelessly .\\nSafety\\nis\\nparamount\\nin\\nthis\\nproject.\\nAn\\nultrasonic\\nsensor\\nmounted\\non\\nthe\\nfront\\nof\\nthe'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Download embeddings from OpenAI\n","embeddings = OpenAIEmbeddings()"],"metadata":{"id":"7GOD7bm-xBUl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docsearch = FAISS.from_texts(texts, embeddings)"],"metadata":{"id":"3nf_vqf1xCTg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docsearch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKs-JnX5xq27","executionInfo":{"status":"ok","timestamp":1702988663836,"user_tz":-330,"elapsed":509,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"f88f4f13-9340-4bf3-e257-af42b444e2bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langchain_community.vectorstores.faiss.FAISS at 0x7f9e28c9ca90>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from langchain.chains.question_answering import load_qa_chain\n","from langchain.llms import OpenAI"],"metadata":{"id":"DIJp7zGgxuY1","executionInfo":{"status":"ok","timestamp":1711780169847,"user_tz":-330,"elapsed":1230,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"],"metadata":{"id":"goujq48Cx2lj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query = \"What sensors are used in the project?\"\n","docs = docsearch.similarity_search(query)\n","chain.run(input_documents=docs, question=query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"T18OLt1Zx5BR","executionInfo":{"status":"ok","timestamp":1702988674834,"user_tz":-330,"elapsed":1570,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"630d7467-3b59-4e10-94ee-e938f43a461b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Flex sensors and ultrasonic sensors.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["query = \"How does the project ensure user safety?\"\n","docs = docsearch.similarity_search(query)\n","chain.run(input_documents=docs, question=query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"8Eb-W3rx6WaL","executionInfo":{"status":"ok","timestamp":1702988679918,"user_tz":-330,"elapsed":2456,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"95880414-21e3-410e-a52d-84fec1f7d362"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" The project ensures user safety by incorporating an ultrasonic sensor mounted on the front of the gloves which continuously measures distances to identify obstacles in the user's path. Real-time feedback is provided to the user to facilitate obstacle avoidance and thereby preventing collisions.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["query = \"What components are used in the project?\"\n","docs = docsearch.similarity_search(query)\n","chain.run(input_documents=docs, question=query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"ZHX7e1uG6aQV","executionInfo":{"status":"ok","timestamp":1702988685880,"user_tz":-330,"elapsed":2545,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"e0812fb2-31ce-430a-ae22-44c749086314"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Flex sensors, an ultrasonic sensor, a microcontroller (e.g., Arduino or Raspberry Pi), actuators (e.g., servo motors, relay modules), a communication module, a power source, and an enclosure.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["query = \"Summarize the IOT-BASED Smart Gloves for Disabled People project\"\n","docs = docsearch.similarity_search(query)\n","chain.run(input_documents=docs, question=query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"3e8pV5wQ8c4b","executionInfo":{"status":"ok","timestamp":1702988868111,"user_tz":-330,"elapsed":3338,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"4600855b-d0dd-444e-f14c-834f8ea8ba53"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' The IOT-Based Smart Gloves for Disabled People project is a groundbreaking endeavor in assistive technology, aimed at significantly improving the lives of people with speech and mobility impairments. The project integrates flex sensors to detect sign language gestures for communication, and ultrasonic sensors for obstacle detection and home automation controlled by hand movements. The design of the gloves includes an enclosure for protection and comfort, and components such as servo motors and relay modules to ensure seamless interaction with home appliances.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["query = \"What is Google Bard?\"\n","docs = docsearch.similarity_search(query)\n","chain.run(input_documents=docs, question=query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"53BFIv7C6fgb","executionInfo":{"status":"ok","timestamp":1702989064111,"user_tz":-330,"elapsed":1200,"user":{"displayName":"assassin wick","userId":"11980377467038755427"}},"outputId":"cb8ac30a-38f4-4043-921f-ab4ab939370e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Google Bard is not relevant to this project.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["query = \"Can the gloves control home devices?\"\n","docs = docsearch.similarity_search(query)\n","chain.run(input_documents=docs, question=query)"],"metadata":{"id":"tw_iNKJBhT97"},"execution_count":null,"outputs":[]}]}